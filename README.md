This project has been a rollercoaster of emotions for me, with moments of disappointment and a constant push to keep going and believe in myself. I am glad that I eventually succeeded in making the project work! 

My initial goal for the project was to create a bot that could scrape data from a website and notify me of any updates. However, I faced many challenges along the way that slowed my progress and required me to rethink my approach.

Soon after I started the project, I forgot about the notification, and I lost the initial purpose by mainly focusing on how to scrape a PDF file (daily crime on the PG County website). I found it extremely difficult to scrape it because it was designed in a way that I kept getting errors. I used ChatGPT and Google, but none were really helpful. Although you suggested I use the Tabula package for parsing the PDF data and converting it to a CSV file, I still struggled with writing the code to scrape the data from the website and updating the CSV file with any new data.

After so much struggle, we decided to change my assignment to the power outage in Maryland on the OpenData website, which was a JSON file. The goal stayed the same (creating a bot that would scrape the updated data and notify me by emailing and messaging me on Slack).
I still used ChatGPT for some of the errors, but with every step I took, I faced a whole different problem, which made me feel disappointed and helpless. Eventually, and with your help, I could write the necessary code, successfully scrape the data, and update the CSV file. I also implemented a script to notify me via Slack whenever new data was added to the CSV file.

Throughout this painful process, I learned the importance of keeping the original code and problem in front of me so I wouldn’t lose track of what I was trying to accomplish. I also realized that it was extremely helpful to break the project into smaller, more manageable tasks and seek guidance and resources when needed.

Honestly, I haven’t thought about the output and how it would look, mainly because I was so much focused on scraping and making a notification bot. But now that I succeeded in completing the project, I definitely can think of what type of output I want from this project. What should I do with the data I have, etc.? As for the storage of data, I can store the new updates I get every day, and I feel like the Slack notification and the emails I get daily to make it easy for me to keep track of the dates I receive the updates. 

In my head, I really like to think of a possible way to design the bot for more complex input, such as a custom search query or filter, which might respond with more detailed information on the data that has been scraped and any relevant updates. For example, the bot could respond with a message: “Here is the latest data for your specified search query. There were ten new results since your last update. Would you like to receive a detailed report via email?" I feel like this would be really cool, or maybe I am mistaken!
Regarding scheduling updates, I believe it would depend on the frequency and significance of updates to the data. If the data changes frequently and is time-sensitive, I would set the bot to check for updates more frequently, perhaps every hour or even every 30 minutes. If the data changes less frequently or is less time-sensitive, I would set the bot to check for updates on a daily or weekly basis.

Overall, this project has taught me so much about web scraping, data parsing, and bot development. It has also challenged me to think creatively and problem-solve in new and different ways. Looking forward to the next step or a new challenge!



